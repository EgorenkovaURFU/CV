{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нестандартные подходы\n",
    "* \"Навешивать\" на модель дополнительные лоссы, то есть минимизировать одновременно несколько функций потерь.\n",
    "* Обучать параллельно на нескольких датасетах и/или несколько моделей. Например, GAN\n",
    "* Следить за тем, что происходит в процессе обучения \n",
    "\n",
    "https://www.tensorflow.org/guide/keras/making_new_layers_and_models_via_subclassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, layers, Sequential\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.metrics import sparse_categorical_accuracy\n",
    "from itertools import permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(-1, 28*28)/255\n",
    "X_test = X_test.reshape(-1, 28*28)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.hidden_layers = [layers.Dense(784, 'relu') for _ in range(2)]\n",
    "        self.head = layers.Dense(10, 'softmax')\n",
    "    \n",
    "    # def call(self, input, training=None, order=None):\n",
    "    #     output = input\n",
    "    #     order = order or np.random.choice(range(2), 2, replace=False)\n",
    "    #     for layer_idx in order:\n",
    "    #         output = self.hidden_layers[layer_idx](output)\n",
    "    #     return self.head(output)\n",
    "    \n",
    "    def call_hidden_layers_in_order(self, input, order):\n",
    "        # note\n",
    "        # Если мы не передаём в .compile() параметры run_eagerly=True, \n",
    "        # то метод .call() вызывается только один раз и строит статический граф вычислений. \n",
    "        # Поэтому такой метод наоборот существенно ускорит обучение и инференс сети.\n",
    "        output = input\n",
    "        for layers_idx in order:\n",
    "            output = self.hidden_layers[layers_idx](output)\n",
    "        return output\n",
    "    \n",
    "    def call(self, input, training=None, order=None):\n",
    "        if order:\n",
    "            output = self.call_hidden_layers_in_order(input, order)\n",
    "        else:\n",
    "            all_possible_orders = list(permutations(range(len(self.hidden_layers)))) # self.hidden_layers_count\n",
    "            all_outputs_dict = {order: self.call_hidden_layers_in_order(input, order) for order in all_possible_orders}\n",
    "            all_outputs = tf.stack(list(all_outputs_dict.values()))\n",
    "            index = tf.random.uniform((), minval=0, maxval=len(all_outputs), dtype=tf.int32)\n",
    "            output = all_outputs[index]\n",
    "        return self.head(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "59/59 [==============================] - 22s 371ms/step - loss: 0.8498 - accuracy: 0.7854 - val_loss: 0.3140 - val_accuracy: 0.9087\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 23s 384ms/step - loss: 0.2731 - accuracy: 0.9180 - val_loss: 0.1953 - val_accuracy: 0.9408\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 20s 342ms/step - loss: 0.1708 - accuracy: 0.9491 - val_loss: 0.1513 - val_accuracy: 0.9548\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 20s 333ms/step - loss: 0.1338 - accuracy: 0.9606 - val_loss: 0.1309 - val_accuracy: 0.9590\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 19s 330ms/step - loss: 0.1079 - accuracy: 0.9679 - val_loss: 0.1150 - val_accuracy: 0.9662\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 20s 338ms/step - loss: 0.0937 - accuracy: 0.9721 - val_loss: 0.0997 - val_accuracy: 0.9694\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 20s 336ms/step - loss: 0.0746 - accuracy: 0.9783 - val_loss: 0.0835 - val_accuracy: 0.9737\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 19s 323ms/step - loss: 0.0649 - accuracy: 0.9816 - val_loss: 0.0811 - val_accuracy: 0.9736\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 21s 356ms/step - loss: 0.0576 - accuracy: 0.9830 - val_loss: 0.0841 - val_accuracy: 0.9740\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 24s 414ms/step - loss: 0.0490 - accuracy: 0.9850 - val_loss: 0.0740 - val_accuracy: 0.9772\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 21s 349ms/step - loss: 0.0427 - accuracy: 0.9877 - val_loss: 0.0909 - val_accuracy: 0.9723\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 21s 353ms/step - loss: 0.0600 - accuracy: 0.9814 - val_loss: 0.0923 - val_accuracy: 0.9701\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 20s 340ms/step - loss: 0.0416 - accuracy: 0.9873 - val_loss: 0.0658 - val_accuracy: 0.9797\n",
      "Epoch 14/20\n",
      "59/59 [==============================] - 21s 349ms/step - loss: 0.0313 - accuracy: 0.9907 - val_loss: 0.0706 - val_accuracy: 0.9780\n",
      "Epoch 15/20\n",
      "59/59 [==============================] - 21s 351ms/step - loss: 0.0281 - accuracy: 0.9919 - val_loss: 0.0693 - val_accuracy: 0.9787\n",
      "Epoch 16/20\n",
      "59/59 [==============================] - 21s 364ms/step - loss: 0.0238 - accuracy: 0.9934 - val_loss: 0.0659 - val_accuracy: 0.9804\n",
      "Epoch 17/20\n",
      "59/59 [==============================] - 20s 343ms/step - loss: 0.0201 - accuracy: 0.9947 - val_loss: 0.0704 - val_accuracy: 0.9783\n",
      "Epoch 18/20\n",
      "59/59 [==============================] - 22s 370ms/step - loss: 0.0214 - accuracy: 0.9941 - val_loss: 0.0620 - val_accuracy: 0.9821\n",
      "Epoch 19/20\n",
      "59/59 [==============================] - 21s 360ms/step - loss: 0.0143 - accuracy: 0.9965 - val_loss: 0.0676 - val_accuracy: 0.9805\n",
      "Epoch 20/20\n",
      "59/59 [==============================] - 21s 355ms/step - loss: 0.0345 - accuracy: 0.9903 - val_loss: 0.1415 - val_accuracy: 0.9580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x11aa5c16be0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CustomModel()\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam', metrics='accuracy',\n",
    "              run_eagerly=True)\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9358\n",
      "0.982\n",
      "0.9759\n"
     ]
    }
   ],
   "source": [
    "# сделаем два предсказания: сначала запустим скрытые слои в одном порядке, затем - в обратном\n",
    "\n",
    "preds1 = model(X_test, order=[0, 1]).numpy()\n",
    "preds2 = model(X_test, order=[1, 0]).numpy()\n",
    "\n",
    "assert not np.array_equal(preds1, preds2)\n",
    "print(np.mean(sparse_categorical_accuracy(y_test, preds1)))\n",
    "print(np.mean(sparse_categorical_accuracy(y_test, preds2)))\n",
    "print(np.mean(sparse_categorical_accuracy(y_test, preds1 + preds2)))\n",
    "\n",
    "# Можно одну нейронку исользовать как ансамбль, запуская для предсказания слои в разном направлении, потом усреднив"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кастомизация цикла обучения\n",
    "\n",
    "* Получаем на вход батч данных\n",
    "* Получаем предсказание модели в режиме обучения и расчиываем loss. <br>\n",
    "Эти операции мы делаем в контексте объекта tf.GradientTape(), чтобы затем получить градиенты.\n",
    "* У каждой модели есть параметр .trainable_variables, в котором хранится список тензоров, являющихся обучаемыми весами модели. Мы обращаемся к этому параметру.\n",
    "* Получаем значения градиентов для тензоров trainable_vars из объекта tf.GradientTape()\n",
    "* Передаем веса и градиенты оптимизатору, который обновляет веса, используя градиенты.\n",
    "* В последних двух строках метода train_step работаем с метриками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSequential(Sequential):\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)\n",
    "            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomSequential([\n",
    "    layers.InputLayer((28*28),),\n",
    "    layers.Dense(784, 'relu'),\n",
    "    layers.Dense(784, 'relu'),\n",
    "    layers.Dense(10, 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "59/59 [==============================] - 10s 133ms/step - loss: 0.4026 - accuracy: 0.8884 - val_loss: 0.1715 - val_accuracy: 0.9510\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 7s 125ms/step - loss: 0.1358 - accuracy: 0.9605 - val_loss: 0.1149 - val_accuracy: 0.9645\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 10s 177ms/step - loss: 0.0859 - accuracy: 0.9748 - val_loss: 0.0851 - val_accuracy: 0.9728\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 10s 176ms/step - loss: 0.0585 - accuracy: 0.9833 - val_loss: 0.0766 - val_accuracy: 0.9752\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 10s 173ms/step - loss: 0.0431 - accuracy: 0.9875 - val_loss: 0.0743 - val_accuracy: 0.9767\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 9s 148ms/step - loss: 0.0312 - accuracy: 0.9912 - val_loss: 0.0607 - val_accuracy: 0.9809\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 8s 134ms/step - loss: 0.0207 - accuracy: 0.9947 - val_loss: 0.0607 - val_accuracy: 0.9798\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 11s 187ms/step - loss: 0.0169 - accuracy: 0.9955 - val_loss: 0.0626 - val_accuracy: 0.9815\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 11s 181ms/step - loss: 0.0136 - accuracy: 0.9966 - val_loss: 0.0598 - val_accuracy: 0.9812\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 11s 193ms/step - loss: 0.0076 - accuracy: 0.9987 - val_loss: 0.0597 - val_accuracy: 0.9825\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 10s 174ms/step - loss: 0.0057 - accuracy: 0.9991 - val_loss: 0.0614 - val_accuracy: 0.9824\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 12s 213ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.0676 - val_accuracy: 0.9806\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 10s 176ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.0657 - val_accuracy: 0.9824\n",
      "Epoch 14/20\n",
      "59/59 [==============================] - 13s 220ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 0.0641 - val_accuracy: 0.9826\n",
      "Epoch 15/20\n",
      "59/59 [==============================] - 9s 155ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0606 - val_accuracy: 0.9841\n",
      "Epoch 16/20\n",
      "59/59 [==============================] - 7s 126ms/step - loss: 9.9170e-04 - accuracy: 1.0000 - val_loss: 0.0615 - val_accuracy: 0.9834\n",
      "Epoch 17/20\n",
      "59/59 [==============================] - 8s 137ms/step - loss: 7.7599e-04 - accuracy: 1.0000 - val_loss: 0.0619 - val_accuracy: 0.9842\n",
      "Epoch 18/20\n",
      "59/59 [==============================] - 8s 130ms/step - loss: 6.2615e-04 - accuracy: 1.0000 - val_loss: 0.0632 - val_accuracy: 0.9841\n",
      "Epoch 19/20\n",
      "59/59 [==============================] - 8s 130ms/step - loss: 5.5292e-04 - accuracy: 1.0000 - val_loss: 0.0642 - val_accuracy: 0.9837\n",
      "Epoch 20/20\n",
      "59/59 [==============================] - 7s 119ms/step - loss: 4.5199e-04 - accuracy: 1.0000 - val_loss: 0.0647 - val_accuracy: 0.9837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x11ad61d4520>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
